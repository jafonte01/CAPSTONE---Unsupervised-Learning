{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 Capstone\n",
    "\n",
    "#### John A. Fonte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Instructions\n",
    "\n",
    "1. Find 100 different entries from at least 10 different authors (articles?)\n",
    "2. Reserve 25% for test set\n",
    "3. cluster vectorized data (go through a few clustering methods)\n",
    "4. Perform unsupervised feature generation and selection\n",
    "5. Perform supervised modeling by classifying by author\n",
    "6. Comment on your 25% holdout group. Did the clusters for the holdout group change dramatically, or were they consistent with the training groups? Is the performance of the model consistent? If not, why?\n",
    "7. Conclude with which models (clustering or not) work best for classifying texts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - combination of NLP and basic imports\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Character</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>EpisodeNo</th>\n",
       "      <th>SEID</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>JERRY</td>\n",
       "      <td>Do you know what this is all about? Do you kno...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>JERRY</td>\n",
       "      <td>(pointing at Georges shirt) See, to me, that b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Are you through?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>JERRY</td>\n",
       "      <td>You do of course try on, when you buy?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Yes, it was purple, I liked it, I dont actuall...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Character                                           Dialogue  \\\n",
       "0           0     JERRY  Do you know what this is all about? Do you kno...   \n",
       "1           1     JERRY  (pointing at Georges shirt) See, to me, that b...   \n",
       "2           2    GEORGE                                   Are you through?   \n",
       "3           3     JERRY             You do of course try on, when you buy?   \n",
       "4           4    GEORGE  Yes, it was purple, I liked it, I dont actuall...   \n",
       "\n",
       "   EpisodeNo    SEID  Season  \n",
       "0        1.0  S01E01     1.0  \n",
       "1        1.0  S01E01     1.0  \n",
       "2        1.0  S01E01     1.0  \n",
       "3        1.0  S01E01     1.0  \n",
       "4        1.0  S01E01     1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data\n",
    "data = pd.read_csv('D:/Github/Data-Science-Bootcamp/CAPSTONE - Unsupervised Learning/seinfeld-chronicles/scripts.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up the DataFrame a little bit\n",
    "data.drop(columns=['Unnamed: 0', 'SEID'], inplace=True)\n",
    "data.rename(columns={'EpisodeNo': 'Episode'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JERRY                                                                                                              14786\n",
       "GEORGE                                                                                                              9708\n",
       "ELAINE                                                                                                              7983\n",
       "KRAMER                                                                                                              6664\n",
       "NEWMAN                                                                                                               640\n",
       "MORTY                                                                                                                505\n",
       "HELEN                                                                                                                471\n",
       "FRANK                                                                                                                436\n",
       "SUSAN                                                                                                                379\n",
       "[Setting                                                                                                             293\n",
       "ESTELLE                                                                                                              286\n",
       "PETERMAN                                                                                                             191\n",
       "PUDDY                                                                                                                162\n",
       "WOMAN                                                                                                                157\n",
       "MAN                                                                                                                  143\n",
       "JACK                                                                                                                 124\n",
       "MICKEY                                                                                                               111\n",
       "BANIA                                                                                                                102\n",
       "STEINBRENNER                                                                                                         101\n",
       "DOCTOR                                                                                                                91\n",
       "CLERK                                                                                                                 90\n",
       "WILHELM                                                                                                               84\n",
       "LIPPMAN                                                                                                               78\n",
       "TIM                                                                                                                   78\n",
       "LEO                                                                                                                   72\n",
       "LLOYD                                                                                                                 72\n",
       "KAREN                                                                                                                 72\n",
       "JACKIE                                                                                                                70\n",
       "UNCLE LEO                                                                                                             70\n",
       "HOYT                                                                                                                  66\n",
       "                                                                                                                   ...  \n",
       "WILLIAMS                                                                                                               1\n",
       "ELAINE (angrily)                                                                                                       1\n",
       "KID #2                                                                                                                 1\n",
       "ELAINE (excited)                                                                                                       1\n",
       "(Through the phone                                                                                                     1\n",
       "% The movie has sold out. ``Real good, George. Real good.'' It's now 10                                                1\n",
       "VOICE ON SPEAKER                                                                                                       1\n",
       "(Helen turns to Jerry and makes a face like                                                                            1\n",
       "ELANE                                                                                                                  1\n",
       "REPORTER                                                                                                               1\n",
       "JERRY (dialing)                                                                                                        1\n",
       "MERYL (not finding the opener)                                                                                         1\n",
       "NEWMAN & KRAMER                                                                                                        1\n",
       "ELAINE (irritated, imitates Gail)                                                                                      1\n",
       "(once again, from the movie we hear this dialogue                                                                      1\n",
       "ELAINE (looking in the fridge)                                                                                         1\n",
       "WORKER (singing)                                                                                                       1\n",
       "[Jenna's Apartment                                                                                                     1\n",
       "PITT (pulling up the socks)                                                                                            1\n",
       "HELEN (in Florida with Morty)                                                                                          1\n",
       "TALL GIRL                                                                                                              1\n",
       "TAPE PLAYER                                                                                                            1\n",
       "KRAMER + JERRY                                                                                                         1\n",
       "SUSAN (O.C.)                                                                                                           1\n",
       "[Jerry's apartment, Jerry and Elaine. Jerry is looking Dream cafe with binoculars. There's a sign on the window        1\n",
       "EVERYBODY                                                                                                              1\n",
       "[GEORGE                                                                                                                1\n",
       "ECHO                                                                                                                   1\n",
       "Elaine (answering)                                                                                                     1\n",
       "OWNER (points at the bottle of maple syrup)                                                                            1\n",
       "Name: Character, Length: 1639, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Character.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JERRY                                                                                                                                                                              15008\n",
       "GEORGE                                                                                                                                                                              9804\n",
       "ELAINE                                                                                                                                                                              8092\n",
       "KRAMER                                                                                                                                                                              6739\n",
       "NEWMAN                                                                                                                                                                               640\n",
       "MORTY                                                                                                                                                                                505\n",
       "HELEN                                                                                                                                                                                471\n",
       "FRANK                                                                                                                                                                                436\n",
       "SUSAN                                                                                                                                                                                379\n",
       "[Setting                                                                                                                                                                             293\n",
       "ESTELLE                                                                                                                                                                              286\n",
       "PETERMAN                                                                                                                                                                             191\n",
       "PUDDY                                                                                                                                                                                162\n",
       "WOMAN                                                                                                                                                                                157\n",
       "MAN                                                                                                                                                                                  143\n",
       "JACK                                                                                                                                                                                 124\n",
       "MICKEY                                                                                                                                                                               111\n",
       "BANIA                                                                                                                                                                                102\n",
       "STEINBRENNER                                                                                                                                                                         101\n",
       "DOCTOR                                                                                                                                                                                91\n",
       "CLERK                                                                                                                                                                                 90\n",
       "WILHELM                                                                                                                                                                               84\n",
       "LIPPMAN                                                                                                                                                                               78\n",
       "TIM                                                                                                                                                                                   78\n",
       "LEO                                                                                                                                                                                   72\n",
       "KAREN                                                                                                                                                                                 72\n",
       "LLOYD                                                                                                                                                                                 72\n",
       "UNCLE LEO                                                                                                                                                                             70\n",
       "JACKIE                                                                                                                                                                                70\n",
       "WAITRESS                                                                                                                                                                              66\n",
       "                                                                                                                                                                                   ...  \n",
       "(Alison though phone)                                                                                                                                                                  1\n",
       "MAN #2                                                                                                                                                                                 1\n",
       "KURT (from the bedroom)                                                                                                                                                                1\n",
       "JULIANNA (visibly uncomfortable)                                                                                                                                                       1\n",
       "[Elaine is still waiting to get into the bathroom-- there's someone in there. *Finally*, a ZZ Top reject comes out of the bathroom and, to paraphrase Jerry in \"The Smelly Car\"        1\n",
       "TOBY (loudly)                                                                                                                                                                          1\n",
       "LOW-TALKER                                                                                                                                                                             1\n",
       "BYSTANDER #2                                                                                                                                                                           1\n",
       "THE FREAK                                                                                                                                                                              1\n",
       "MERYL (getting up)                                                                                                                                                                     1\n",
       "RADIO ANNOUNCER                                                                                                                                                                        1\n",
       "EXECUTIVE 2                                                                                                                                                                            1\n",
       "Check #1246, dated Dec. 15 Â‘96, Made out to                                                                                                                                            1\n",
       "SUSAN (to Lena)                                                                                                                                                                        1\n",
       "ALL FOUR MEN                                                                                                                                                                           1\n",
       "Stu                                                                                                                                                                                    1\n",
       "ICE CREAM VENDER #1                                                                                                                                                                    1\n",
       "[ACT ONE SCENE A INT. ESCALATOR - GOING DOWN TO A GARAGE. IN SINGLE FILE                                                                                                               1\n",
       "(The race is on and Pappanick is slowly making ground. Kramer is pounding himself imitating the jockey and shouts                                                                      1\n",
       "(Two clocks at a table, both 4                                                                                                                                                         1\n",
       "MAN #                                                                                                                                                                                  1\n",
       "Ex                                                                                                                                                                                     1\n",
       "NEWMAN (coyly)                                                                                                                                                                         1\n",
       "(We see Kramer, groaning and holding his stomach, running down the hall, and opening the bathroom's door. Someone in there says                                                        1\n",
       "ANNOUNCER ON P.A. SYSTEM                                                                                                                                                               1\n",
       "Elaine (thinking it's Dan)                                                                                                                                                             1\n",
       "TOBY (standing)                                                                                                                                                                        1\n",
       "DR. BURKE                                                                                                                                                                              1\n",
       "(Fade to the next morning, the alarm clock goes off, it's 5                                                                                                                            1\n",
       "OWNER (points at the bottle of maple syrup)                                                                                                                                            1\n",
       "Name: Character, Length: 1287, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By virtue of the above's results, we will need to do a bit of cleaning:\n",
    "df = data.copy() # keeping original dataset\n",
    "\n",
    "import re\n",
    "\n",
    "df.Character.replace(r'.*JERRY.*$', 'JERRY', regex=True, inplace=True)\n",
    "df.Character.replace(r'.*GEORGE.*$', 'GEORGE', regex=True, inplace=True)\n",
    "df.Character.replace(r'.*ELAINE.*$', 'ELAINE', regex=True, inplace=True)\n",
    "df.Character.replace(r'.*KRAMER.*$', 'KRAMER', regex=True, inplace=True)\n",
    "\n",
    "df.Character.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JERRY                                                       15040\n",
       "GEORGE                                                       9813\n",
       "ELAINE                                                       8116\n",
       "KRAMER                                                       6751\n",
       "NEWMAN                                                        640\n",
       "MORTY                                                         505\n",
       "HELEN                                                         471\n",
       "FRANK                                                         436\n",
       "SUSAN                                                         379\n",
       "[Setting                                                      293\n",
       "ESTELLE                                                       286\n",
       "PETERMAN                                                      191\n",
       "PUDDY                                                         162\n",
       "WOMAN                                                         157\n",
       "MAN                                                           143\n",
       "JACK                                                          124\n",
       "MICKEY                                                        111\n",
       "BANIA                                                         102\n",
       "STEINBRENNER                                                  101\n",
       "DOCTOR                                                         91\n",
       "CLERK                                                          90\n",
       "WILHELM                                                        84\n",
       "TIM                                                            78\n",
       "LIPPMAN                                                        78\n",
       "LEO                                                            72\n",
       "KAREN                                                          72\n",
       "LLOYD                                                          72\n",
       "UNCLE LEO                                                      70\n",
       "JACKIE                                                         70\n",
       "HOYT                                                           66\n",
       "                                                            ...  \n",
       "SUPERVISOR                                                      1\n",
       "LEO (O.C.)                                                      1\n",
       "ELIANE                                                          1\n",
       "OLD WOMAN                                                       1\n",
       "MAN 4                                                           1\n",
       "MR. CROSS                                                       1\n",
       "MORTY(V.O.)                                                     1\n",
       "*Note                                                           1\n",
       "ANNOUNCER ON TV                                                 1\n",
       "RICKEY                                                          1\n",
       "[The Intervention [NOTE                                         1\n",
       "DISPATCHER                                                      1\n",
       "INTERVIEWER                                                     1\n",
       "MARCELLINO                                                      1\n",
       "TENANT 2                                                        1\n",
       "Dugan                                                           1\n",
       "WOMANEWMAN                                                      1\n",
       "VOICE ON INTERCOM                                               1\n",
       "PHILBIN                                                         1\n",
       "BYSTANDER #1                                                    1\n",
       "GIRL (NOT WINONA)                                               1\n",
       "Opening scene                                                   1\n",
       "RUSTY                                                           1\n",
       "VOICE FROM POKER GAME                                           1\n",
       "% In the background is the plot complication of the week        1\n",
       "MODEL #1                                                        1\n",
       "BETSY (to Aunt May)                                             1\n",
       "MARTY (looking at the locket)                                   1\n",
       "MARCELINO (leaving)                                             1\n",
       "OWNER (points at the bottle of maple syrup)                     1\n",
       "Name: Character, Length: 1212, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# did not ignore case, so will do replacements one more time\n",
    "\n",
    "df['Character'] = df.Character.str.replace(r'.*JERRY.*$', 'JERRY', regex=True, flags=re.IGNORECASE)\n",
    "df['Character'] = df.Character.str.replace(r'.*GEORGE.*$', 'GEORGE', regex=True, flags=re.IGNORECASE)\n",
    "df['Character'] = df.Character.str.replace(r'.*ELAINE.*$', 'ELAINE', regex=True, flags=re.IGNORECASE)\n",
    "df['Character'] = df.Character.str.replace(r'.*KRAMER.*$', 'KRAMER', regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "df.Character.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.Character == 'JERRY') | (df.Character == 'GEORGE') | \n",
    "       (df.Character == 'ELAINE') | (df.Character == 'KRAMER') | (df.Character == 'NEWMAN') | (df.Character == 'MORTY') | \n",
    "       (df.Character == 'HELEN') | (df.Character == 'FRANK') | (df.Character == 'SUSAN') | (df.Character == 'ESTELLE')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehotencoder for character classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-9983a84d240c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCharacter\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1283\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1284\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "df_test = df.iloc[df.Character > 200]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>Do you know what this is all about? Do you kno...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>(pointing at Georges shirt) See, to me, that b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Are you through?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>You do of course try on, when you buy?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Yes, it was purple, I liked it, I dont actuall...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Character                                           Dialogue  Episode  \\\n",
       "0     JERRY  Do you know what this is all about? Do you kno...      1.0   \n",
       "1     JERRY  (pointing at Georges shirt) See, to me, that b...      1.0   \n",
       "2    GEORGE                                   Are you through?      1.0   \n",
       "3     JERRY             You do of course try on, when you buy?      1.0   \n",
       "4    GEORGE  Yes, it was purple, I liked it, I dont actuall...      1.0   \n",
       "\n",
       "   Season  \n",
       "0     1.0  \n",
       "1     1.0  \n",
       "2     1.0  \n",
       "3     1.0  \n",
       "4     1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42437 entries, 0 to 54615\n",
      "Data columns (total 4 columns):\n",
      "Character    42437 non-null object\n",
      "Dialogue     42434 non-null object\n",
      "Episode      42437 non-null float64\n",
      "Season       42437 non-null float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>Do you know what this is all about? Do you know, why were here? To be out, this is out...and out is one of the single most enjoyable experiences o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>(pointing at Georges shirt) See, to me, that button is in the worst possible spot. The second button literally makes or breaks the shirt, look at ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Are you through?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>You do of course try on, when you buy?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Yes, it was purple, I liked it, I dont actually recall considering the buttons.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Character  \\\n",
       "0     JERRY   \n",
       "1     JERRY   \n",
       "2    GEORGE   \n",
       "3     JERRY   \n",
       "4    GEORGE   \n",
       "\n",
       "                                                                                                                                                Dialogue  \\\n",
       "0  Do you know what this is all about? Do you know, why were here? To be out, this is out...and out is one of the single most enjoyable experiences o...   \n",
       "1  (pointing at Georges shirt) See, to me, that button is in the worst possible spot. The second button literally makes or breaks the shirt, look at ...   \n",
       "2                                                                                                                                       Are you through?   \n",
       "3                                                                                                                 You do of course try on, when you buy?   \n",
       "4                                                                        Yes, it was purple, I liked it, I dont actually recall considering the buttons.   \n",
       "\n",
       "   Episode  Season  \n",
       "0      1.0     1.0  \n",
       "1      1.0     1.0  \n",
       "2      1.0     1.0  \n",
       "3      1.0     1.0  \n",
       "4      1.0     1.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resizing column widths\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating text cleaner function because spaCy is finnecky\n",
    "\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\-\\-',' ', str(text))\n",
    "    text = re.sub(r'[\\[].*?[\\]]', ' ', str(text))\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JERRY      15040\n",
       "GEORGE      9813\n",
       "ELAINE      8116\n",
       "KRAMER      6751\n",
       "NEWMAN       640\n",
       "MORTY        505\n",
       "HELEN        471\n",
       "FRANK        436\n",
       "SUSAN        379\n",
       "ESTELLE      286\n",
       "Name: Character, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Character.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Dialogue'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(pointing at Georges shirt) See, to me, that button is in the worst possible spot. The second button literally makes or breaks the shirt, look at it. Its too high! Its in no-mans-land. You look like you live with your mother.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplequote = df['Dialogue'][1]\n",
    "text_cleaner(samplequote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Dialogue'] = df['Dialogue'].apply(lambda x: text_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42437.000000</td>\n",
       "      <td>42437.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.159531</td>\n",
       "      <td>5.604944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.732658</td>\n",
       "      <td>2.260228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Episode        Season\n",
       "count  42437.000000  42437.000000\n",
       "mean      11.159531      5.604944\n",
       "std        6.732658      2.260228\n",
       "min        1.000000      1.000000\n",
       "25%        5.000000      4.000000\n",
       "50%       11.000000      6.000000\n",
       "75%       17.000000      8.000000\n",
       "max       24.000000      9.000000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and Y\n",
    "X = df.Dialogue\n",
    "y = df.Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize data using tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.65,         # drop words that are too common (i.e., found in more than 65% of tokens)\n",
    "                             min_df=2,            # only use words that appear twice\n",
    "                             stop_words='english',# takes out stopwords - very helpful!\n",
    "                             lowercase=True,      # done intentionally to ignore capitalization differences\n",
    "                             use_idf=True,        # yes please\n",
    "                             norm=u'l2',          # L2 regularization - handy with large number of features generated from vectorization\n",
    "                             smooth_idf=True      # prevents divide by zero errors by adding 1 to vectorized values\n",
    "                            )               \n",
    "#Applying the vectorizer\n",
    "\n",
    "#parents_sents_tfidf = []\n",
    "\n",
    "#for sent in parents_sents:\n",
    " #   print(sent)\n",
    "  #  vectorized_sent = vectorizer.fit_transform(sent)\n",
    "   # parents_sents_tfidf.append(vectorized_sent)\n",
    "\n",
    "df['Vectorized Dialogue'] = df.Dialogue.apply(lambda x: vectorizer.fit_transform(x.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data with 25% holdout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1) # default holdout parameter is test_size = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "X_pca = PCA(2).fit_transform(X_norm) # cutting the large vectorized data down to two dimensions\n",
    "y_pred = KMeans(n_clusters=2, random_state=42).fit_predict(X_pca)\n",
    "\n",
    "# Plot the solution.\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred)\n",
    "plt.show()\n",
    "\n",
    "# Check the solution against the data.\n",
    "print('Comparing k-means clusters against the data:')\n",
    "print(pd.crosstab(y_pred, y)) # pandas version of confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatchkmeans = MiniBatchKMeans(\n",
    "    init='random',\n",
    "    n_clusters=2,\n",
    "    batch_size=200)\n",
    "minibatchkmeans.fit(X_pca)\n",
    "\n",
    "# Add the new predicted cluster memberships to the data frame.\n",
    "predict_mini = minibatchkmeans.predict(X_pca)\n",
    "\n",
    "# Check the MiniBatch model against our earlier one.\n",
    "print('Comparing k-means and mini batch k-means solutions:')\n",
    "print(pd.crosstab(predict_mini, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "# Here we set the bandwidth. This function automatically derives a bandwidth\n",
    "# number based on an inspection of the distances among points in the data.\n",
    "bandwidth = estimate_bandwidth(X_train, quantile=0.2, n_samples=500)\n",
    "\n",
    "# Declare and fit the model.\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms.fit(X_train)\n",
    "\n",
    "# Extract cluster assignments for each data point.\n",
    "labels = ms.labels_\n",
    "\n",
    "# Coordinates of the cluster centers.\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# Count our clusters.\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "\n",
    "print(\"Number of estimated clusters: {}\".format(n_clusters_))\n",
    "\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=labels)\n",
    "plt.show()\n",
    "\n",
    "print('Comparing the assigned categories to the ones in the data:')\n",
    "print(pd.crosstab(y_train,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Declare the model and fit it in one statement.\n",
    "# Note that you can provide arguments to the model, but we didn't.\n",
    "af = AffinityPropagation().fit(X_train)\n",
    "print('Done')\n",
    "\n",
    "# Pull the number of clusters and cluster assignments for each data point.\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "labels = af.labels_\n",
    "\n",
    "print('Estimated number of clusters: {}'.format(n_clusters_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "# Cycle through each cluster and graph them with a center point for the\n",
    "# exemplar and lines from the exemplar to each data point in the cluster.\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters_), colors):\n",
    "    class_members = labels == k\n",
    "    cluster_center = X_train[cluster_centers_indices[k]]\n",
    "    plt.plot(X_train[class_members, 0], X_train[class_members, 1], col + '.')\n",
    "    plt.plot(cluster_center[0],\n",
    "             cluster_center[1],\n",
    "             'o',\n",
    "             markerfacecolor=col,\n",
    "             markeredgecolor='k')\n",
    "    for x in X_train[class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.title('Estimated number of clusters: {}'.format(n_clusters_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In each of the above graphs, also include code for graphing X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradise_doc = nlp(paradise)\n",
    "paradise_sents = [[sent, \"Milton\"] for sent in paradise_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[Paradise Lost by John Milton 1667] \n",
       "   \n",
       "   , 'Milton'], [Book I \n",
       "   \n",
       "   \n",
       "  Of Man's first disobedience, and the fruit \n",
       "  Of that forbidden tree whose mortal taste \n",
       "  Brought death into the World, and all our woe, \n",
       "  With loss of Eden, till one greater Man \n",
       "  Restore us, and regain the blissful seat, \n",
       "  Sing,, 'Milton'], [Heavenly Muse, that, on the secret top \n",
       "  Of Oreb, or of Sinai, didst inspire \n",
       "  That shepherd who first taught the chosen seed \n",
       "  In the beginning how the heavens and earth \n",
       "  Rose out of Chaos: or, if Sion hill ,\n",
       "  'Milton'], [Delight thee more, and Siloa's brook that flowed \n",
       "  Fast by the oracle of God, 'Milton'], [, I thence \n",
       "  Invoke thy aid to my adventurous song, \n",
       "  That with no middle flight intends to soar \n",
       "  Above th' Aonian mount, while it pursues \n",
       "  Things unattempted yet in prose or rhyme. , 'Milton']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paradise_sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = gutenberg.raw('edgeworth-parents.txt')\n",
    "\n",
    "parents = text_cleaner(parents)\n",
    "\n",
    "parents_doc = nlp(parents)\n",
    "parents_sents = [[sent, \"Edgeworth\"] for sent in parents_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_sents = [sent for sent in parents_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[THE ORPHANS.,\n",
       " Near the ruins of the castle of Rossmore, in Ireland, is a small cabin, in which there once lived a widow and her four children.,\n",
       " As long as she was able to work, she was very industrious, and was accounted the best spinner in the parish; but she overworked herself at last, and fell ill, so that she could not sit to her wheel as she used to do, and was obliged to give it up to her eldest daughter, Mary.,\n",
       " Mary was at this time about twelve years old.,\n",
       " One evening she was sitting at the foot of her mother's bed spinning, and her little brothers and sisters were gathered round the fire eating their potatoes and milk for supper.]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents_sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.span.Span' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-0c0be3edfa38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m    \u001b[1;31m# parents_sents_tfidf.append(vectorized_sent)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mparents_sents_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparents_doc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparents_sents_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \"\"\"\n\u001b[0;32m   1602\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1603\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1604\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1032\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    326\u001b[0m                                                tokenize)\n\u001b[0;32m    327\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 328\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.span.Span' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.65,\n",
    "                             min_df=5,   \n",
    "                             stop_words='english', \n",
    "                             lowercase=True,\n",
    "                             use_idf=True,  \n",
    "                             norm=u'l2',    \n",
    "                             smooth_idf=True\n",
    "                            )               \n",
    "#Applying the vectorizer\n",
    "\n",
    "#parents_sents_tfidf = []\n",
    "\n",
    "#for sent in parents_sents:\n",
    " #   print(sent)\n",
    "  #  vectorized_sent = vectorizer.fit_transform(sent)\n",
    "   # parents_sents_tfidf.append(vectorized_sent)\n",
    "\n",
    "parents_sents_tfidf = vectorizer.fit_transform(parents_doc.sents)\n",
    "print(parents_sents_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECURSION NOTES 4/17\n",
    "\n",
    "https://www.educative.io/d/data_structures\n",
    "    \n",
    "    https://www.educative.io/collection/5642554087309312/5634727314718720\n",
    "        \n",
    "        https://medium.com/educative/3-month-coding-interview-bootcamp-904422926ce8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
