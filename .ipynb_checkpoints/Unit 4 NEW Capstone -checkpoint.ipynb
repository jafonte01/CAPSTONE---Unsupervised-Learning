{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4 Capstone - News Article Analysis & Classification\n",
    "\n",
    "## John A. Fonte\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Find 100 different entries from at least 10 different authors (articles?)\n",
    "2. Reserve 25% for test set\n",
    "3. cluster vectorized data (go through a few clustering methods)\n",
    "4. Perform unsupervised feature generation and selection\n",
    "5. Perform supervised modeling by classifying by author\n",
    "6. Comment on your 25% holdout group. Did the clusters for the holdout group change dramatically, or were they consistent with the training groups? Is the performance of the model consistent? If not, why?\n",
    "7. Conclude with which models (clustering or not) work best for classifying texts.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "__Source:__ https://archive.ics.uci.edu/ml/datasets/Reuter_50_50#\n",
    "\n",
    "__Description:__ This is a subset of the [Reuters Corpus Volume 1 (RCV1)](https://scikit-learn.org/0.17/datasets/rcv1.html). Specifically, this subset consists of the top 50 authors by article proliferation, with a total of 100 articles per each author within the combined training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 1. Data Load and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading Data from Local Computer\n",
    "Each author is a subfolder, and within each folder is a series of .txt files\n",
    "The goal of this cell is to load all the contents of every subfolder into the \n",
    "DataFrame, while retaining the author designation for those works.\n",
    "'''\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "def multiple_file_load(file_directory):\n",
    "    \n",
    "    # identifying all author subfolders - appending them into list \n",
    "    \n",
    "    authorlist = []\n",
    "    textlist = []\n",
    "    \n",
    "    for author in listdir(file_directory):\n",
    "        authorname = str(author)\n",
    "        author_sub_directory = (file_directory + '/' + author) #author file path\n",
    "    \n",
    "    # identifying all files within each subfolder - \n",
    "    \n",
    "        for filename in listdir(author_sub_directory):\n",
    "            text_file_path = (author_sub_directory + '/' + filename) # text file path\n",
    "            \n",
    "            if (filename.lower().endswith('txt')):\n",
    "                authorlist.append(authorname)\n",
    "                textfile = open(text_file_path,'r') # this is how you open files\n",
    "                substantive_text = textfile.read()  # this is how to read a file\n",
    "                textlist.append(substantive_text)   # this is how to do something with that file\n",
    "                textfile.close()                    # this is how to close the file \n",
    "                                                             # (you must close one before opening another!)\n",
    "  # pushing the two lists into a dataframe \n",
    "\n",
    "    df = pd.DataFrame({'Author':authorlist, 'Text':textlist})\n",
    "    \n",
    "    return df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading training data (note the file path)\n",
    "df_train = multiple_file_load('D:/Github/Data-Science-Bootcamp/CAPSTONE - Unsupervised Learning/C50/C50train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AaronPressman</td>\n",
       "      <td>The Internet may be overflowing with new techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AaronPressman</td>\n",
       "      <td>The U.S. Postal Service announced Wednesday a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AaronPressman</td>\n",
       "      <td>Elementary school students with access to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AaronPressman</td>\n",
       "      <td>An influential Internet organisation has backe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AaronPressman</td>\n",
       "      <td>An influential Internet organisation has backe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Author                                               Text\n",
       "0  AaronPressman  The Internet may be overflowing with new techn...\n",
       "1  AaronPressman  The U.S. Postal Service announced Wednesday a ...\n",
       "2  AaronPressman  Elementary school students with access to the ...\n",
       "3  AaronPressman  An influential Internet organisation has backe...\n",
       "4  AaronPressman  An influential Internet organisation has backe..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the space in the authors...because I want it\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_split = [re.findall('[A-Z][a-z]*', i) for i in df_train.Author]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Aaron', 'Pressman'],\n",
       " ['Aaron', 'Pressman'],\n",
       " ['Aaron', 'Pressman'],\n",
       " ['Aaron', 'Pressman'],\n",
       " ['Aaron', 'Pressman']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_split[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining them back together\n",
    "author_join = []\n",
    "\n",
    "for couple in author_split:\n",
    "    joined_string = couple[0] + ' ' + couple[1]\n",
    "    author_join.append(joined_string)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China's central bank chief has said that infla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China ushered in 1997, a year it has hailed as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China issued tough new rules on the handling o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China will avoid bold moves in tackling its ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>Communist Party chief Jiang Zemin has put his ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Author                                               Text\n",
       "2495  William Kazer  China's central bank chief has said that infla...\n",
       "2496  William Kazer  China ushered in 1997, a year it has hailed as...\n",
       "2497  William Kazer  China issued tough new rules on the handling o...\n",
       "2498  William Kazer  China will avoid bold moves in tackling its ai...\n",
       "2499  William Kazer  Communist Party chief Jiang Zemin has put his ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Author'] = pd.Series(author_join)\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AaronPressman</td>\n",
       "      <td>U.S. Senators on Tuesday sharply criticized a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AaronPressman</td>\n",
       "      <td>Two members of Congress criticised the Federal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AaronPressman</td>\n",
       "      <td>Commuters stuck in traffic on the Leesburg Pik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AaronPressman</td>\n",
       "      <td>A broad coalition of corporations went to Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AaronPressman</td>\n",
       "      <td>On the Internet, where new products come and g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Author                                               Text\n",
       "0  AaronPressman  U.S. Senators on Tuesday sharply criticized a ...\n",
       "1  AaronPressman  Two members of Congress criticised the Federal...\n",
       "2  AaronPressman  Commuters stuck in traffic on the Leesburg Pik...\n",
       "3  AaronPressman  A broad coalition of corporations went to Capi...\n",
       "4  AaronPressman  On the Internet, where new products come and g..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before I begin adding features, assignment asks for 25% data split, NOT 50/50\n",
    "# Going to have to concat some of those testing articles\n",
    "df_test = multiple_file_load('D:/Github/Data-Science-Bootcamp/CAPSTONE - Unsupervised Learning/C50/C50test')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another fix to Author column\n",
    "\n",
    "author_split = [re.findall('[A-Z][a-z]*', i) for i in df_test.Author]\n",
    "\n",
    "author_join = []\n",
    "\n",
    "for couple in author_split:\n",
    "    joined_string = couple[0] + ' ' + couple[1]\n",
    "    author_join.append(joined_string)    \n",
    "    \n",
    "df_test['Author'] = pd.Series(author_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GOAL:\n",
    "Trying to get half of the datapoints OF EACH AUTHOR\n",
    "in the testing set into a new DataFrame, which\n",
    "will be concatenated onto the training set.\n",
    "I will delete that from the testing set later.\n",
    "\n",
    "Doing this instead of combining both and splitting 75/25 later \n",
    "ensures balanced data between the authors.\n",
    "'''\n",
    "\n",
    "def appendingdataframe(dataframe):\n",
    "    appendabledataframe = pd.DataFrame(columns=['Author', 'Text'])\n",
    "    \n",
    "    for item in dataframe.Author.unique():\n",
    "        print(\"Looping through \", item)\n",
    "        df_testauthor = df_test[df_test['Author'] == item].copy() \n",
    "        appendabledataframe = appendabledataframe.append(df_testauthor[25:], \n",
    "                                                         ignore_index=True) # want half of df_testauthor!\n",
    "    \n",
    "    return appendabledataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping through  Aaron Pressman\n",
      "Looping through  Alan Crosby\n",
      "Looping through  Alexander Smith\n",
      "Looping through  Benjamin Kang\n",
      "Looping through  Bernard Hickey\n",
      "Looping through  Brad Dorfman\n",
      "Looping through  Darren Schuettler\n",
      "Looping through  David Lawder\n",
      "Looping through  Edna Fernandes\n",
      "Looping through  Eric Auchard\n",
      "Looping through  Fumiko Fujisaki\n",
      "Looping through  Graham Earnshaw\n",
      "Looping through  Heather Scoffield\n",
      "Looping through  Jane Macartney\n",
      "Looping through  Jan Lopatka\n",
      "Looping through  Jim Gilchrist\n",
      "Looping through  Joe Ortiz\n",
      "Looping through  John Mastrini\n",
      "Looping through  Jonathan Birt\n",
      "Looping through  Jo Winterbottom\n",
      "Looping through  Karl Penhaul\n",
      "Looping through  Keith Weir\n",
      "Looping through  Kevin Drawbaugh\n",
      "Looping through  Kevin Morrison\n",
      "Looping through  Kirstin Ridley\n",
      "Looping through  Kourosh Karimkhany\n",
      "Looping through  Lydia Zajc\n",
      "Looping through  Lynne O\n",
      "Looping through  Lynnley Browning\n",
      "Looping through  Marcel Michelson\n",
      "Looping through  Mark Bendeich\n",
      "Looping through  Martin Wolk\n",
      "Looping through  Matthew Bunce\n",
      "Looping through  Michael Connor\n",
      "Looping through  Mure Dickie\n",
      "Looping through  Nick Louth\n",
      "Looping through  Patricia Commins\n",
      "Looping through  Peter Humphrey\n",
      "Looping through  Pierre Tran\n",
      "Looping through  Robin Sidel\n",
      "Looping through  Roger Fillion\n",
      "Looping through  Samuel Perry\n",
      "Looping through  Sarah Davison\n",
      "Looping through  Scott Hillis\n",
      "Looping through  Simon Cowell\n",
      "Looping through  Tan Ee\n",
      "Looping through  Therese Poletti\n",
      "Looping through  Tim Farrand\n",
      "Looping through  Todd Nissen\n",
      "Looping through  William Kazer\n"
     ]
    }
   ],
   "source": [
    "# using appendabledataframe to avoid screwing up original data\n",
    "# This is explicit inefficiency at the cost of being cautious\n",
    "\n",
    "df_train2 = df_train.append(appendingdataframe(df_train), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if the appending worked\n",
    "len(df_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping through  Aaron Pressman\n",
      "Looping through  Alan Crosby\n",
      "Looping through  Alexander Smith\n",
      "Looping through  Benjamin Kang\n",
      "Looping through  Bernard Hickey\n",
      "Looping through  Brad Dorfman\n",
      "Looping through  Darren Schuettler\n",
      "Looping through  David Lawder\n",
      "Looping through  Edna Fernandes\n",
      "Looping through  Eric Auchard\n",
      "Looping through  Fumiko Fujisaki\n",
      "Looping through  Graham Earnshaw\n",
      "Looping through  Heather Scoffield\n",
      "Looping through  Jane Macartney\n",
      "Looping through  Jan Lopatka\n",
      "Looping through  Jim Gilchrist\n",
      "Looping through  Joe Ortiz\n",
      "Looping through  John Mastrini\n",
      "Looping through  Jonathan Birt\n",
      "Looping through  Jo Winterbottom\n",
      "Looping through  Karl Penhaul\n",
      "Looping through  Keith Weir\n",
      "Looping through  Kevin Drawbaugh\n",
      "Looping through  Kevin Morrison\n",
      "Looping through  Kirstin Ridley\n",
      "Looping through  Kourosh Karimkhany\n",
      "Looping through  Lydia Zajc\n",
      "Looping through  Lynne O\n",
      "Looping through  Lynnley Browning\n",
      "Looping through  Marcel Michelson\n",
      "Looping through  Mark Bendeich\n",
      "Looping through  Martin Wolk\n",
      "Looping through  Matthew Bunce\n",
      "Looping through  Michael Connor\n",
      "Looping through  Mure Dickie\n",
      "Looping through  Nick Louth\n",
      "Looping through  Patricia Commins\n",
      "Looping through  Peter Humphrey\n",
      "Looping through  Pierre Tran\n",
      "Looping through  Robin Sidel\n",
      "Looping through  Roger Fillion\n",
      "Looping through  Samuel Perry\n",
      "Looping through  Sarah Davison\n",
      "Looping through  Scott Hillis\n",
      "Looping through  Simon Cowell\n",
      "Looping through  Tan Ee\n",
      "Looping through  Therese Poletti\n",
      "Looping through  Tim Farrand\n",
      "Looping through  Todd Nissen\n",
      "Looping through  William Kazer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doing same for df_test\n",
    "\n",
    "df_test2 = df_test.append(appendingdataframe(df_train), ignore_index=True)\n",
    "\n",
    "# checking if the appending worked\n",
    "len(df_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now to drop the rows added to df_train from df_test\n",
    "\n",
    "df_test2.drop_duplicates(keep=False, inplace=True)\n",
    "len(df_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Features\n",
    "\n",
    "Just some fun numerical features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding some numerical features for text analysis\n",
    "\n",
    "df_train['Raw Character Count'] = df_train['Text'].apply(lambda x: len(x))\n",
    "df_train['Raw Word Count'] = df_train['Text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing same for df_test\n",
    "\n",
    "df_test['Raw Character Count'] = df_test['Text'].apply(lambda x: len(x))\n",
    "df_test['Raw Word Count'] = df_test['Text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating numerical classes for authors:\n",
    "# I feel like one hot encoding would've screwed things up, so I did \"factorize\"\n",
    "\n",
    "df_train['AuthorNum'] = pd.factorize(df_train.Author)[0]\n",
    "df_train['AuthorNum'] = df_train['AuthorNum'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "      <th>Raw Character Count</th>\n",
       "      <th>Raw Word Count</th>\n",
       "      <th>AuthorNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China has scored new successes in its fight ag...</td>\n",
       "      <td>2473</td>\n",
       "      <td>411</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China has scored new successes in its fight ag...</td>\n",
       "      <td>2473</td>\n",
       "      <td>411</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China is on target with plans to to promote 10...</td>\n",
       "      <td>1742</td>\n",
       "      <td>287</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China may need to adjust the mix of its treasu...</td>\n",
       "      <td>3263</td>\n",
       "      <td>546</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>A Chinese ideologue known for his strictly ort...</td>\n",
       "      <td>3026</td>\n",
       "      <td>483</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Author                                               Text  \\\n",
       "3745  William Kazer  China has scored new successes in its fight ag...   \n",
       "3746  William Kazer  China has scored new successes in its fight ag...   \n",
       "3747  William Kazer  China is on target with plans to to promote 10...   \n",
       "3748  William Kazer  China may need to adjust the mix of its treasu...   \n",
       "3749  William Kazer  A Chinese ideologue known for his strictly ort...   \n",
       "\n",
       "      Raw Character Count  Raw Word Count AuthorNum  \n",
       "3745                 2473             411        49  \n",
       "3746                 2473             411        49  \n",
       "3747                 1742             287        49  \n",
       "3748                 3263             546        49  \n",
       "3749                 3026             483        49  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and same for df_test...\n",
    "\n",
    "df_test['AuthorNum'] = pd.factorize(df_test.Author)[0]\n",
    "df_test['AuthorNum'] = df_test['AuthorNum'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "      <th>Raw Character Count</th>\n",
       "      <th>Raw Word Count</th>\n",
       "      <th>AuthorNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China's Foreign Minister Qian Qichen on Friday...</td>\n",
       "      <td>1827</td>\n",
       "      <td>299</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China blamed criminal elements on Sunday for a...</td>\n",
       "      <td>3156</td>\n",
       "      <td>516</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>An unemployed Taiwanese journalist on Monday d...</td>\n",
       "      <td>3000</td>\n",
       "      <td>492</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>China moved ahead on Wednesday with plans to h...</td>\n",
       "      <td>3762</td>\n",
       "      <td>590</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>William Kazer</td>\n",
       "      <td>Premier Li Peng said on Friday China wanted a ...</td>\n",
       "      <td>2417</td>\n",
       "      <td>408</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Author                                               Text  \\\n",
       "2470  William Kazer  China's Foreign Minister Qian Qichen on Friday...   \n",
       "2471  William Kazer  China blamed criminal elements on Sunday for a...   \n",
       "2472  William Kazer  An unemployed Taiwanese journalist on Monday d...   \n",
       "2473  William Kazer  China moved ahead on Wednesday with plans to h...   \n",
       "2474  William Kazer  Premier Li Peng said on Friday China wanted a ...   \n",
       "\n",
       "      Raw Character Count  Raw Word Count AuthorNum  \n",
       "2470                 1827             299        49  \n",
       "2471                 3156             516        49  \n",
       "2472                 3000             492        49  \n",
       "2473                 3762             590        49  \n",
       "2474                 2417             408        49  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a \"Meaningful Word Count\" via spacy implementation\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "df_train['Spacy-ed Text'] = pd.Series([nlp(text) for text in df_train.Text])\n",
    "\n",
    "# Spacy-ing will take a LONG LONG LONG LONNNNNNNNNGGGGGGG TIME TO LOAD. BE PATIENT!\n",
    "# run-time (about five minutes for df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Spacy-ed Text'] = pd.Series([nlp(text) for text in df_test.Text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter # good to know that it exists\n",
    "\n",
    "def lemma_frequencies(text, include_stop=True):\n",
    "    \n",
    "    # Build a list of lemmas.\n",
    "    # Strip out punctuation and, optionally, stop words.\n",
    "    lemmas = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            lemmas.append(token.lemma_)\n",
    "            \n",
    "    # Build and return a Counter object containing word counts.\n",
    "    return Counter(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Meaningful Word Count'] = pd.Series([lemma_frequencies(text) for text in df_train['Spacy-ed Text']])\n",
    "df_test['Meaningful Word Count'] = pd.Series([lemma_frequencies(text) for text in df_test['Spacy-ed Text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testna['raw char count'] = len(df_testna['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing! Changing Text to Numbers\n",
    "\n",
    "Once everything is numerical, then we can feed that data into the clusters for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
